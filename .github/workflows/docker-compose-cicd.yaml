name: CI with Docker Compose

on:
  push:
    branches: [ unittest ]
  pull_request:
    branches: [ '*' ]

jobs:
  # --------------------
  # 1. UNIT TEST JOB
  # --------------------
  unit-tests:
    name: Run dags Unit Tests 
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Free disk space before tests
      run: |
        echo "Disk before cleanup:"
        df -h
        sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/lib/android /opt/hostedtoolcache
        echo "Disk after cleanup:"
        df -h
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Set PYTHONPATH
      run: echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV

    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements-ci.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        pip install -r airflow/requirements.txt

    - name: Set DAGS_FOLDER environment variable
      run: echo "DAGS_FOLDER=$airflow/dags" >> $GITHUB_ENV

    - name: Run Unit Tests
      run: |
        for dir in tests/test_dags; do
          if [ -d "$dir" ] && [ "$(find $dir -type f -name 'test_*.py' -exec grep -q 'def test_' {} \; -print)" ]; then
            echo "Running tests in $dir"
            pytest $dir || exit 1
          else
            echo "Skipping $dir â€” no test functions found"
          fi
        done

  # --------------------
  # 2. INTEGRATION / DOCKER JOB
  # --------------------
  build-and-test:
    name: Run integration tests in Docker
    runs-on: ubuntu-latest
    needs: unit-tests

    services:
      docker:
        image: docker:latest
        options: --privileged

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Free disk space before build
      run: |
        echo "Disk before cleanup:"
        df -h
        sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/lib/android /opt/hostedtoolcache
        echo "Disk after cleanup:"
        df -h
        
    - name: Cache Docker layers
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-docker-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-docker-

    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements-ci.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-


    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Set up Docker Compose
      run: |
        sudo apt-get update
        sudo apt-get install -y docker-compose

    - name: Set environment variables
      run: |
        echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
        echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
        echo "AWS_DEFAULT_REGION=${{ secrets.AWS_DEFAULT_REGION }}" >> $GITHUB_ENV
        echo "AIRFLOW_UID=${{ secrets.AIRFLOW_UID }}" >> $GITHUB_ENV
        echo "MINIO_ENDPOINT=${{ secrets.MINIO_ENDPOINT }}" >> $GITHUB_ENV

    - name: Build and run containers
      run: |
        DOCKER_BUILDKIT=1 COMPOSE_DOCKER_CLI_BUILD=1 docker-compose -p testproject -f docker-compose.yaml up -d --build

    # - name: Copy and install test dependencies
    #   run: |
    #     for service in fastapi-api airflow-webserver streamlit; do
    #       docker cp requirements-ci.txt testproject_${service}_1:/tmp/requirements-ci.txt
    #       docker-compose -p testproject exec -T $service pip install --no-cache-dir -r /tmp/requirements-ci.txt
    #     done


    # - name: Run containers tests
    #   run: |
    #     docker-compose -p testproject exec -T fastapi-api pytest tests/test_api || exit 1
    #     docker-compose -p testproject exec -T airflow-webserver pytest tests/test_dags || exit 1
    #     docker-compose -p testproject exec -T fastapi-api pytest tests/test_src || exit 1
    #     docker-compose -p testproject exec -T streamlit pytest tests/test_streamlit || exit 1

    - name: Reduce verbosity in logs
      run: |
        export GITHUB_RUNNER_VERBOSE=0

    - name: Run health checks and wait for services to be healthy
      run: |
        urls=(
          "http://localhost:3000/health"
          "http://localhost:9001/health"
          "http://localhost:9090"
          "http://localhost:5001/health"
          "http://localhost:8501"
          "http://localhost:8080/health"
        )
        
        for url in "${urls[@]}"; do
          for i in {1..10}; do
            if curl --fail "$url"; then
              echo "Service at $url is healthy"
              break
            fi
            echo "Service at $url is not healthy, retrying in 5 seconds..."
            sleep 5
          done
        done

    - name: Shut down containers and clean up temporary files
      run: |
        docker-compose down
        rm -rf /tmp/*
        rm -rf ~/.cache/* 